{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47086b59-21ee-428b-a27e-db5131982ef8",
   "metadata": {},
   "source": [
    "### Lesson 06 - Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff97f8b0-4b2d-4f09-8f4a-acf64f6e11ae",
   "metadata": {},
   "source": [
    "#### 1. Download Data, Unzip and Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "863ecfa6-1320-4ae1-9b17-e1543324fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import urllib.request as req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec55515a-cb54-469f-bb6e-c351927b517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "data_url = \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eda6196c-20d6-4a30-a7a5-428399e22c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hymenoptera_data directory created\n"
     ]
    }
   ],
   "source": [
    "# create a directory\n",
    "def create_dirs(dir_path):\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    print(f\"{dir_path} directory created\")\n",
    "\n",
    "ROOT_DATA_DIR = \"hymenoptera_data\"\n",
    "\n",
    "create_dirs(ROOT_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de034ce5-96c6-4455-bb96-a7bfb105e493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading data\n",
      "filename: hymenoptera_data\\data.zip created with info \n",
      " Content-Type: application/zip\n",
      "Content-Length: 47286322\n",
      "Connection: close\n",
      "Date: Wed, 24 Jan 2024 12:10:09 GMT\n",
      "Last-Modified: Wed, 15 Mar 2017 18:46:00 GMT\n",
      "ETag: \"5f8c32a6554f6acb4d649776e7735e48\"\n",
      "x-amz-version-id: null\n",
      "Accept-Ranges: bytes\n",
      "Server: AmazonS3\n",
      "X-Cache: Miss from cloudfront\n",
      "Via: 1.1 0261a45edf9fa8a52158083448fcb032.cloudfront.net (CloudFront)\n",
      "X-Amz-Cf-Pop: BOM78-P4\n",
      "X-Amz-Cf-Id: MS7FZlPBXeUfpexwktOhkBk4fCCOc3Os-b6KwfW86dA1yLbks_4ZkQ==\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download data\n",
    "data_zip_file = \"data.zip\"\n",
    "data_zip_path = os.path.join(ROOT_DATA_DIR, data_zip_file)\n",
    "\n",
    "if not os.path.isfile(data_zip_file):\n",
    "    print(\"downloading data\")\n",
    "    filename, headers = req.urlretrieve(data_url, data_zip_path)\n",
    "    print(f\"filename: {filename} created with info \\n {headers}\")\n",
    "\n",
    "else:\n",
    "    print(\"file is already present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9c98542-bc59-4b27-b97c-1d0ccae5d969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip data\n",
    "from zipfile import ZipFile\n",
    "\n",
    "unzip_data_dirname = \"unzip_data_dir\"\n",
    "unzip_data_dir = os.path.join(ROOT_DATA_DIR, unzip_data_dirname)\n",
    "\n",
    "if not os.path.isfile(unzip_data_dir):\n",
    "    os.makedirs(unzip_data_dir, exist_ok=True)\n",
    "    with ZipFile(data_zip_path) as f:\n",
    "        f.extractall(unzip_data_dir)\n",
    "\n",
    "else:\n",
    "    print(f\"data already extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5dbec38-7ca9-42f4-b596-e039c45f3e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0be9116-959c-46ba-a77f-be554a992cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = Path(\"hymenoptera_data/unzip_data_dir/hymenoptera_data/train\")\n",
    "test_path = Path(\"hymenoptera_data/unzip_data_dir/hymenoptera_data/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0758863f-6148-4b77-9489-be195588bb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b467251f-a4c2-4ee8-a46b-64237cf89117",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.tensor([0.5, 0.5, 0.5])\n",
    "std = torch.tensor([0.5, 0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "630d7fb8-6941-44eb-b085-d49bb6d766d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82ce8cc4-6ec2-4244-82fc-43d1b98b1b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(root=train_path, transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(root=train_path, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08a896b0-5e51-4388-af77-b9255d133593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ants': 0, 'bees': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0872e508-eacb-421b-8a95-484975ebc915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ants': 0, 'bees': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = train_data.class_to_idx\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c00b5e7-65a8-47b8-9770-31a68370623d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 244\n",
       "    Root location: hymenoptera_data\\unzip_data_dir\\hymenoptera_data\\train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
       "               ToTensor()\n",
       "               Normalize(mean=tensor([0.5000, 0.5000, 0.5000]), std=tensor([0.5000, 0.5000, 0.5000]))\n",
       "           )"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51f2bd58-ecc6-49e7-ad46-fb05333e5eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5a2bbcb-221a-4787-9fd9-5470fcf37327",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1e36651-fee8-4f27-bff4-db32cb0fbdd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c627689-8ed6-43d8-902c-b543ff5190f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a759d97-a37f-434a-9507-f050a31c6f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 224, 224])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0999aefc-3048-4916-a47d-2177c363ca0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cbc70b-2a4c-4971-9f45-5c9a6d22f89d",
   "metadata": {},
   "source": [
    "#### 2. Download and Use Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad4a2a38-f8f4-4b26-a35b-82bd3ee4fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3aef44f7-3345-483d-bd9a-1ce0e238ebbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "decfed37-29e7-4d90-a25b-70e5a251e90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_32f55\">\n",
       "  <caption>Total trainable: 61100840, non trainable: 0 </caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_32f55_level0_col0\" class=\"col_heading level0 col0\" >Modules</th>\n",
       "      <th id=\"T_32f55_level0_col1\" class=\"col_heading level0 col1\" >Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_32f55_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_32f55_row0_col0\" class=\"data row0 col0\" >features.0.weight</td>\n",
       "      <td id=\"T_32f55_row0_col1\" class=\"data row0 col1\" >23232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_32f55_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_32f55_row1_col0\" class=\"data row1 col0\" >features.0.bias</td>\n",
       "      <td id=\"T_32f55_row1_col1\" class=\"data row1 col1\" >64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_32f55_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_32f55_row2_col0\" class=\"data row2 col0\" >features.3.weight</td>\n",
       "      <td id=\"T_32f55_row2_col1\" class=\"data row2 col1\" >307200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_32f55_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_32f55_row3_col0\" class=\"data row3 col0\" >features.3.bias</td>\n",
       "      <td id=\"T_32f55_row3_col1\" class=\"data row3 col1\" >192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_32f55_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_32f55_row4_col0\" class=\"data row4 col0\" >features.6.weight</td>\n",
       "      <td id=\"T_32f55_row4_col1\" class=\"data row4 col1\" >663552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_32f55_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_32f55_row5_col0\" class=\"data row5 col0\" >features.6.bias</td>\n",
       "      <td id=\"T_32f55_row5_col1\" class=\"data row5 col1\" >384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_32f55_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_32f55_row6_col0\" class=\"data row6 col0\" >features.8.weight</td>\n",
       "      <td id=\"T_32f55_row6_col1\" class=\"data row6 col1\" >884736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_32f55_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_32f55_row7_col0\" class=\"data row7 col0\" >features.8.bias</td>\n",
       "      <td id=\"T_32f55_row7_col1\" class=\"data row7 col1\" >256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_32f55_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_32f55_row8_col0\" class=\"data row8 col0\" >features.10.weight</td>\n",
       "      <td id=\"T_32f55_row8_col1\" class=\"data row8 col1\" >589824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_32f55_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_32f55_row9_col0\" class=\"data row9 col0\" >features.10.bias</td>\n",
       "      <td id=\"T_32f55_row9_col1\" class=\"data row9 col1\" >256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_32f55_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_32f55_row10_col0\" class=\"data row10 col0\" >classifier.1.weight</td>\n",
       "      <td id=\"T_32f55_row10_col1\" class=\"data row10 col1\" >37748736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_32f55_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_32f55_row11_col0\" class=\"data row11 col0\" >classifier.1.bias</td>\n",
       "      <td id=\"T_32f55_row11_col1\" class=\"data row11 col1\" >4096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_32f55_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_32f55_row12_col0\" class=\"data row12 col0\" >classifier.4.weight</td>\n",
       "      <td id=\"T_32f55_row12_col1\" class=\"data row12 col1\" >16777216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_32f55_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_32f55_row13_col0\" class=\"data row13 col0\" >classifier.4.bias</td>\n",
       "      <td id=\"T_32f55_row13_col1\" class=\"data row13 col1\" >4096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_32f55_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_32f55_row14_col0\" class=\"data row14 col0\" >classifier.6.weight</td>\n",
       "      <td id=\"T_32f55_row14_col1\" class=\"data row14 col1\" >4096000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_32f55_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_32f55_row15_col0\" class=\"data row15 col0\" >classifier.6.bias</td>\n",
       "      <td id=\"T_32f55_row15_col1\" class=\"data row15 col1\" >1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d36e324c90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_both_params(model):\n",
    "    model_params = {\"Modules\": list(), \"Parameters\": list()}\n",
    "    total = {\"trainable\": 0, \"non_trainable\": 0}\n",
    "    \n",
    "    for name, parameters in model.named_parameters():\n",
    "        param = parameters.numel()\n",
    "        if not parameters.requires_grad:\n",
    "            total[\"non_trainable\"] += param\n",
    "            continue\n",
    "        model_params[\"Modules\"].append(name)\n",
    "        model_params[\"Parameters\"].append(param)\n",
    "        total[\"trainable\"] += param\n",
    "    df = pd.DataFrame(model_params)\n",
    "    df = df.style.set_caption(f\"\"\"Total trainable: {total[\"trainable\"]}, non trainable: {total[\"non_trainable\"]} \"\"\")\n",
    "    return df\n",
    "\n",
    "count_both_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cd78eb2-8bcb-4d38-84dd-74081adb6e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing all the model layers\n",
    "for parameters in model.parameters():\n",
    "    parameters.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a9c7621-2e30-4264-baf0-0516ceb2aac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_b5128\">\n",
       "  <caption>Total trainable: 0, non trainable: 61100840 </caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b5128_level0_col0\" class=\"col_heading level0 col0\" >Modules</th>\n",
       "      <th id=\"T_b5128_level0_col1\" class=\"col_heading level0 col1\" >Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d36e1db7d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_both_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c75d5a4a-056d-40e6-bf9c-9e5c9ebae5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.5, inplace=False)\n",
       "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Dropout(p=0.5, inplace=False)\n",
       "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32b20d33-7422-40db-b84d-ed928bb4f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(in_features=9216, out_features=100, bias=True),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.5, inplace=False),\n",
    "    nn.Linear(in_features=100, out_features=2, bias=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96d35b4c-7dfe-4469-ac17-a502f67e4e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=9216, out_features=100, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=100, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70c7d0f3-abd2-46af-aabc-91f1ab844f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_cd2c3\">\n",
       "  <caption>Total trainable: 921902, non trainable: 2469696 </caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_cd2c3_level0_col0\" class=\"col_heading level0 col0\" >Modules</th>\n",
       "      <th id=\"T_cd2c3_level0_col1\" class=\"col_heading level0 col1\" >Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_cd2c3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_cd2c3_row0_col0\" class=\"data row0 col0\" >classifier.0.weight</td>\n",
       "      <td id=\"T_cd2c3_row0_col1\" class=\"data row0 col1\" >921600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd2c3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_cd2c3_row1_col0\" class=\"data row1 col0\" >classifier.0.bias</td>\n",
       "      <td id=\"T_cd2c3_row1_col1\" class=\"data row1 col1\" >100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd2c3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_cd2c3_row2_col0\" class=\"data row2 col0\" >classifier.3.weight</td>\n",
       "      <td id=\"T_cd2c3_row2_col1\" class=\"data row2 col1\" >200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd2c3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_cd2c3_row3_col0\" class=\"data row3 col0\" >classifier.3.bias</td>\n",
       "      <td id=\"T_cd2c3_row3_col1\" class=\"data row3 col1\" >2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d36e569dd0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_both_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9082d185-5fcf-4f69-9623-9810b964e234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13b1785-97fa-4653-909f-cd0fea964199",
   "metadata": {},
   "source": [
    "#### 3. Train our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54adeb23-77f5-4509-b3b3-61e25f6731fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "139d3d12-7772-4031-bd47-1be319f6f1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:08<00:00,  2.24s/it, loss=0.385]\n",
      "Epoch 2/20: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.46s/it, loss=0.119]\n",
      "Epoch 3/20: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.62s/it, loss=0.127]\n",
      "Epoch 4/20: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.52s/it, loss=0.0815]\n",
      "Epoch 5/20: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.52s/it, loss=0.138]\n",
      "Epoch 6/20: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.48s/it, loss=0.0294]\n",
      "Epoch 7/20: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.45s/it, loss=0.0351]\n",
      "Epoch 8/20: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.46s/it, loss=0.00963]\n",
      "Epoch 9/20: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.45s/it, loss=0.0232]\n",
      "Epoch 10/20: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.45s/it, loss=0.00989]\n",
      "Epoch 11/20: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.41s/it, loss=0.0347]\n",
      "Epoch 12/20: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.48s/it, loss=0.00396]\n",
      "Epoch 13/20: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.43s/it, loss=0.00688]\n",
      "Epoch 14/20: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.58s/it, loss=0.0085]\n",
      "Epoch 15/20: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.50s/it, loss=0.0108]\n",
      "Epoch 16/20: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.52s/it, loss=0.0122]\n",
      "Epoch 17/20: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.48s/it, loss=0.000815]\n",
      "Epoch 18/20: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.51s/it, loss=0.00208]\n",
      "Epoch 19/20: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.60s/it, loss=0.00206]\n",
      "Epoch 20/20: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.47s/it, loss=0.00165]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    with tqdm(train_loader) as tqdm_epoch:\n",
    "        for images, labels in tqdm_epoch:\n",
    "            tqdm_epoch.set_description(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            tqdm_epoch.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5fbbbf6a-6c60-4213-a76b-2554163c4347",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_MODEL_DIR = \"Lesson_06_models\"\n",
    "os.makedirs(ROOT_MODEL_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_FILE = \"Trans_model.pth\"\n",
    "MODEL_FILE_PATH = os.path.join(ROOT_MODEL_DIR, MODEL_FILE)\n",
    "\n",
    "\n",
    "torch.save(model, MODEL_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8465b8f7-611f-455e-9679-39e428e5ca97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
